{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f88802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import metatensor\n",
    "from ase.io import read\n",
    "from metatensor import TensorBlock, TensorMap,Labels\n",
    "from itertools import product\n",
    "import ase\n",
    "\n",
    "from rascaline import NeighborList\n",
    "\n",
    "# from anisotropic_gaussian_moments_expansion import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "be3ad947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to compute all moments for a general dilation matrix.\n",
    "# The implementation focuses on conceptual simplicity, while sacrifizing\n",
    "# memory efficiency.\n",
    "def compute_moments_inefficient_implementation(A, a, maxdeg):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - A: symmetric 3x3 matrix (np.ndarray of shape (3,3))\n",
    "        Dilation matrix of the Gaussian that determines its shape.\n",
    "        It can be written as cov = RDR^T, where R is a rotation matrix that specifies\n",
    "        the orientation of the three principal axes, while D is a diagonal matrix\n",
    "        whose three diagonal elements are the lengths of the principal axes.\n",
    "    - a: np.ndarray of shape (3,)\n",
    "        Contains the position vector for the center of the trivariate Gaussian.\n",
    "    - maxdeg: int\n",
    "        Maximum degree for which the moments need to be computed.\n",
    "        \n",
    "    Returns:\n",
    "    - The list of moments defined as\n",
    "        <x^n0 * y^n1 * z^n2> = integral (x^n0 * y^n1 * z^n2) * exp(-0.5*(r-a).T@cov@(r-a)) dxdydz\n",
    "        Note that the term \"moments\" in probability theory are defined for normalized Gaussian distributions.\n",
    "        Here, we take the Gaussian \n",
    "    \"\"\"\n",
    "    # Make sure that the provided arrays have the correct dimensions and properties\n",
    "    assert A.shape == (3,3), \"Dilation matrix needs to be 3x3\"\n",
    "    assert np.sum((A-A.T)**2) < 1e-14, \"Dilation matrix needs to be symmetric\"\n",
    "    assert a.shape == (3,1), \"Center of Gaussian has to be given by a 3-dim. vector\"\n",
    "    assert maxdeg > 0, \"The maximum degree needs to be at least 1\"\n",
    "    cov = np.linalg.inv(A) # the covariance matrix is the inverse of the matrix A\n",
    "    global_factor = (2*np.pi)**1.5 / np.sqrt(np.linalg.det(A)) # normalization of Gaussian\n",
    "    \n",
    "    # Initialize the array in which to store the moments\n",
    "    # moments[n0, n1, n2] will be set to <x^n0 * y^n1 * z^n2>\n",
    "    # This representation is memory inefficient, since only about 1/3 of the\n",
    "    # array elements will actually be relevant.\n",
    "    # The advantage, however, is the simplicity in later use.\n",
    "    moments = np.zeros((maxdeg+1, maxdeg+1, maxdeg+1))\n",
    "    \n",
    "    # Initialize the first few elements\n",
    "    moments[0,0,0] = 1.\n",
    "    moments[1,0,0] = a[0] # <x>\n",
    "    moments[0,1,0] = a[1] # <y>\n",
    "    moments[0,0,1] = a[2] # <z>\n",
    "    if maxdeg == 1:\n",
    "        return global_factor * moments\n",
    "    \n",
    "    # Initialize the quadratic elements\n",
    "    moments[2,0,0] = cov[0,0] + a[0]**2\n",
    "    moments[0,2,0] = cov[1,1] + a[1]**2\n",
    "    moments[0,0,2] = cov[2,2] + a[2]**2\n",
    "    moments[1,1,0] = cov[0,1] + a[0]*a[1]\n",
    "    moments[0,1,1] = cov[1,2] + a[1]*a[2]\n",
    "    moments[1,0,1] = cov[2,0] + a[2]*a[0]\n",
    "    if maxdeg == 2:\n",
    "        return global_factor * moments\n",
    "    \n",
    "    # Iterate over all possible exponents to generate all moments\n",
    "    # Instead of iterating over n1, n2 and n3, we iterate over the total degree of the monomials\n",
    "    # which will allow us to simplify certain edge cases.\n",
    "    for deg in range(2, maxdeg):\n",
    "        for n0 in range(deg+1):\n",
    "            for n1 in range(deg+1-n0):\n",
    "                # We consider monomials of degree \"deg\", and generate moments of degree deg+1.\n",
    "                n2 = deg - n0 - n1\n",
    "                \n",
    "                # Run the x-iteration\n",
    "                moments[n0+1,n1,n2] = a[0]*moments[n0,n1,n2] + cov[0,0]*n0*moments[n0-1,n1,n2]\n",
    "                moments[n0+1,n1,n2] += cov[0,1]*n1*moments[n0,n1-1,n2] + cov[0,2]*n2*moments[n0,n1,n2-1]\n",
    "                \n",
    "                # If n0 is equal to zero, we also need the y- and z-iterations\n",
    "                if n0 == 0:\n",
    "                    # Run the y-iteration\n",
    "                    moments[n0,n1+1,n2] = a[1]*moments[n0,n1,n2] + cov[1,0]*n0*moments[n0-1,n1,n2]\n",
    "                    moments[n0,n1+1,n2] += cov[1,1]*n1*moments[n0,n1-1,n2] + cov[1,2]*n2*moments[n0,n1,n2-1]\n",
    "                    \n",
    "                    if n0 == 0 and n1 == 0:\n",
    "                        # Run the z-iteration\n",
    "                        moments[n0,n1,n2+1] = a[2]*moments[n0,n1,n2] + cov[2,0]*n0*moments[n0-1,n1,n2]\n",
    "                        moments[n0,n1,n2+1] += cov[2,1]*n1*moments[n0,n1-1,n2] + cov[2,2]*n2*moments[n0,n1,n2-1]\n",
    "    \n",
    "    return global_factor * moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d3f4c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {\n",
    "    \"interaction_cutoff\": 4.5, # need to define the neighborlist \n",
    "    \"A\": np.eye(3),#anisotropy/dilation matrix\n",
    "    \"maxdeg\":5 # max degree of expansion \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "08310918",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = read('/Users/jigyasa/scratch/data_papers/data/water/dataset/water_randomized_1000.xyz', ':2')\n",
    "for f in frames: \n",
    "    f.pbc=False\n",
    "#     f.pbc=True\n",
    "#     f.cell = [5,5,5]\n",
    "#     f.center()\n",
    "global_species = np.unique(np.hstack([np.unique(f.numbers) for f in frames]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c10ac989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use rascaline to get the full neighborlist \n",
    "nl = NeighborList(hypers[\"interaction_cutoff\"], True).compute(frames)\n",
    "\n",
    "#nl is a tensormap with keys ('species_first_atom', 'species_second_atom')\n",
    "#depending on the cutoff some species pairs may not appear \n",
    "#self pairs are not present but in PBC pairs between copies of the same atom are accounted for\n",
    "\n",
    "# nl.keys_to_properties('species_second_atom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1ecc4017",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma =0.3\n",
    "A = hypers[\"A\"]*sigma**2\n",
    "maxdeg = hypers[\"maxdeg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "46fe883f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6, 6, 1)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_value.reshape((sample_value.shape)+(1,)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "34841140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accumulate the blocks for the pairwise expansion - \n",
    "desc_blocks=[]\n",
    "for center_species in global_species:\n",
    "    for neighbor_species in global_species:\n",
    "        if (center_species, neighbor_species) in nl.keys:\n",
    "            nl_block = nl.block(species_first_atom=center_species, species_second_atom=neighbor_species)\n",
    "            desc_block_values = []\n",
    "            for isample, nl_sample in enumerate(nl_block.samples):\n",
    "                x,y,z = nl_block.values[isample,0], nl_block.values[isample,1],nl_block.values[isample,2]\n",
    "                sample_value=compute_moments_inefficient_implementation(A, np.array([x,y,z]), maxdeg) #moments for the pair\n",
    "                #this is a (maxdeg+1, maxdeg+1, maxdeg+1) matrix\n",
    "                desc_block_values.append(sample_value.reshape((sample_value.shape)+(1,)))\n",
    "                \n",
    "#                 print(sample_value.shape)\n",
    "#             desc_blocks.append(TensorBlock(values = np.asarray(desc_block_values),\n",
    "#                                       samples = nl_block.samples,\n",
    "#                                       components = [Labels(),Labels(),Labels()]\n",
    "#                                       properties = [Labels([\"dummy\"], [\"0\"])]\n",
    "            \n",
    "            \n",
    "#                                         )\n",
    "                         \n",
    "#                          )\n",
    "# pair_aniso_desc = TensorMap(nl.keys, desc_blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3ad37e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labels([(1, 0), (8, 0)],\n",
       "       dtype=[('species_second_atom', '<i4'), ('distance', '<i4')])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the final descriptor, we just need to sum over the neighbor species \n",
    "\n",
    "desc_blocks = []\n",
    "for center_species in global_species:\n",
    "    for neighbor_species in global_species:\n",
    "        if (center_species, neighbor_species) in pair_aniso_desc.keys:\n",
    "            desc_samples=[]\n",
    "            pair_block = pair_aniso_desc.block(species_first_atom=center_species, species_second_atom=neighbor_species)\n",
    "            desc_block_values = []\n",
    "            desc_samples = list(product(np.unique(block.samples['structure']), np.unique(block.samples['center'])))\n",
    "            for isample, sample in enumerate(desc_samples):\n",
    "                sample_idx = [idx for idx, tup in enumerate(nl_block.samples) if tup['structure']==sample[0] and tup['center']==sample[1]]\n",
    "                \n",
    "                sample_value+= desc_block_values.append(nl_block.values[sample_idx].sum(axis=0))\n",
    "                desc_block_values.append(sample_value)\n",
    "#             desc_blocks.append(TensorBlock(values = np.asarray(desc_block_values),\n",
    "#                                       samples = Labels([\"structure\", \"central_atom\"], desc_samples),\n",
    "#                                       components = [Labels()]\n",
    "#                                       properties = [Labels()]\n",
    "            \n",
    "            \n",
    "#                                         )\n",
    "\n",
    "aniso_desc = TensorMap(Labels(\"center_species\", np.asarray(global_species, dtype=int32)), desc_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab8fac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
