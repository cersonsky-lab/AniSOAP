{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f88802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import metatensor\n",
    "from ase.io import read\n",
    "from metatensor import TensorBlock, TensorMap, Labels\n",
    "from itertools import product\n",
    "import ase\n",
    "\n",
    "from rascaline import NeighborList\n",
    "\n",
    "# from anisotropic_gaussian_moments_expansion import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "be3ad947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to compute all moments for a general dilation matrix.\n",
    "# The implementation focuses on conceptual simplicity, while sacrifizing\n",
    "# memory efficiency.\n",
    "def compute_moments_inefficient_implementation(A, a, maxdeg):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - A: symmetric 3x3 matrix (np.ndarray of shape (3,3))\n",
    "        Dilation matrix of the Gaussian that determines its shape.\n",
    "        It can be written as cov = RDR^T, where R is a rotation matrix that specifies\n",
    "        the orientation of the three principal axes, while D is a diagonal matrix\n",
    "        whose three diagonal elements are the lengths of the principal axes.\n",
    "    - a: np.ndarray of shape (3,)\n",
    "        Contains the position vector for the center of the trivariate Gaussian.\n",
    "    - maxdeg: int\n",
    "        Maximum degree for which the moments need to be computed.\n",
    "\n",
    "    Returns:\n",
    "    - The list of moments defined as\n",
    "        <x^n0 * y^n1 * z^n2> = integral (x^n0 * y^n1 * z^n2) * exp(-0.5*(r-a).T@cov@(r-a)) dxdydz\n",
    "        Note that the term \"moments\" in probability theory are defined for normalized Gaussian distributions.\n",
    "        Here, we take the Gaussian\n",
    "    \"\"\"\n",
    "    # Make sure that the provided arrays have the correct dimensions and properties\n",
    "    assert A.shape == (3, 3), \"Dilation matrix needs to be 3x3\"\n",
    "    assert np.sum((A - A.T) ** 2) < 1e-14, \"Dilation matrix needs to be symmetric\"\n",
    "    assert a.shape == (3, 1), \"Center of Gaussian has to be given by a 3-dim. vector\"\n",
    "    assert maxdeg > 0, \"The maximum degree needs to be at least 1\"\n",
    "    cov = np.linalg.inv(A)  # the covariance matrix is the inverse of the matrix A\n",
    "    global_factor = (2 * np.pi) ** 1.5 / np.sqrt(\n",
    "        np.linalg.det(A)\n",
    "    )  # normalization of Gaussian\n",
    "\n",
    "    # Initialize the array in which to store the moments\n",
    "    # moments[n0, n1, n2] will be set to <x^n0 * y^n1 * z^n2>\n",
    "    # This representation is memory inefficient, since only about 1/3 of the\n",
    "    # array elements will actually be relevant.\n",
    "    # The advantage, however, is the simplicity in later use.\n",
    "    moments = np.zeros((maxdeg + 1, maxdeg + 1, maxdeg + 1))\n",
    "\n",
    "    # Initialize the first few elements\n",
    "    moments[0, 0, 0] = 1.0\n",
    "    moments[1, 0, 0] = a[0]  # <x>\n",
    "    moments[0, 1, 0] = a[1]  # <y>\n",
    "    moments[0, 0, 1] = a[2]  # <z>\n",
    "    if maxdeg == 1:\n",
    "        return global_factor * moments\n",
    "\n",
    "    # Initialize the quadratic elements\n",
    "    moments[2, 0, 0] = cov[0, 0] + a[0] ** 2\n",
    "    moments[0, 2, 0] = cov[1, 1] + a[1] ** 2\n",
    "    moments[0, 0, 2] = cov[2, 2] + a[2] ** 2\n",
    "    moments[1, 1, 0] = cov[0, 1] + a[0] * a[1]\n",
    "    moments[0, 1, 1] = cov[1, 2] + a[1] * a[2]\n",
    "    moments[1, 0, 1] = cov[2, 0] + a[2] * a[0]\n",
    "    if maxdeg == 2:\n",
    "        return global_factor * moments\n",
    "\n",
    "    # Iterate over all possible exponents to generate all moments\n",
    "    # Instead of iterating over n1, n2 and n3, we iterate over the total degree of the monomials\n",
    "    # which will allow us to simplify certain edge cases.\n",
    "    for deg in range(2, maxdeg):\n",
    "        for n0 in range(deg + 1):\n",
    "            for n1 in range(deg + 1 - n0):\n",
    "                # We consider monomials of degree \"deg\", and generate moments of degree deg+1.\n",
    "                n2 = deg - n0 - n1\n",
    "\n",
    "                # Run the x-iteration\n",
    "                moments[n0 + 1, n1, n2] = (\n",
    "                    a[0] * moments[n0, n1, n2]\n",
    "                    + cov[0, 0] * n0 * moments[n0 - 1, n1, n2]\n",
    "                )\n",
    "                moments[n0 + 1, n1, n2] += (\n",
    "                    cov[0, 1] * n1 * moments[n0, n1 - 1, n2]\n",
    "                    + cov[0, 2] * n2 * moments[n0, n1, n2 - 1]\n",
    "                )\n",
    "\n",
    "                # If n0 is equal to zero, we also need the y- and z-iterations\n",
    "                if n0 == 0:\n",
    "                    # Run the y-iteration\n",
    "                    moments[n0, n1 + 1, n2] = (\n",
    "                        a[1] * moments[n0, n1, n2]\n",
    "                        + cov[1, 0] * n0 * moments[n0 - 1, n1, n2]\n",
    "                    )\n",
    "                    moments[n0, n1 + 1, n2] += (\n",
    "                        cov[1, 1] * n1 * moments[n0, n1 - 1, n2]\n",
    "                        + cov[1, 2] * n2 * moments[n0, n1, n2 - 1]\n",
    "                    )\n",
    "\n",
    "                    if n0 == 0 and n1 == 0:\n",
    "                        # Run the z-iteration\n",
    "                        moments[n0, n1, n2 + 1] = (\n",
    "                            a[2] * moments[n0, n1, n2]\n",
    "                            + cov[2, 0] * n0 * moments[n0 - 1, n1, n2]\n",
    "                        )\n",
    "                        moments[n0, n1, n2 + 1] += (\n",
    "                            cov[2, 1] * n1 * moments[n0, n1 - 1, n2]\n",
    "                            + cov[2, 2] * n2 * moments[n0, n1, n2 - 1]\n",
    "                        )\n",
    "\n",
    "    return global_factor * moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d3f4c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {\n",
    "    \"interaction_cutoff\": 4.5,  # need to define the neighborlist\n",
    "    \"A\": np.eye(3),  # anisotropy/dilation matrix\n",
    "    \"maxdeg\": 5,  # max degree of expansion\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "08310918",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = read(\n",
    "    \"/Users/jigyasa/scratch/data_papers/data/water/dataset/water_randomized_1000.xyz\",\n",
    "    \":2\",\n",
    ")\n",
    "for f in frames:\n",
    "    f.pbc = False\n",
    "#     f.pbc=True\n",
    "#     f.cell = [5,5,5]\n",
    "#     f.center()\n",
    "global_species = np.unique(np.hstack([np.unique(f.numbers) for f in frames]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c10ac989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use rascaline to get the full neighborlist\n",
    "nl = NeighborList(hypers[\"interaction_cutoff\"], True).compute(frames)\n",
    "\n",
    "# nl is a tensormap with keys ('species_first_atom', 'species_second_atom')\n",
    "# depending on the cutoff some species pairs may not appear\n",
    "# self pairs are not present but in PBC pairs between copies of the same atom are accounted for\n",
    "\n",
    "# nl.keys_to_properties('species_second_atom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1ecc4017",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.3\n",
    "A = hypers[\"A\"] * sigma**2\n",
    "maxdeg = hypers[\"maxdeg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "46fe883f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6, 6, 1)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_value.reshape((sample_value.shape) + (1,)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "34841140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumulate the blocks for the pairwise expansion -\n",
    "desc_blocks = []\n",
    "for center_species in global_species:\n",
    "    for neighbor_species in global_species:\n",
    "        if (center_species, neighbor_species) in nl.keys:\n",
    "            nl_block = nl.block(\n",
    "                species_first_atom=center_species, species_second_atom=neighbor_species\n",
    "            )\n",
    "            desc_block_values = []\n",
    "            for isample, nl_sample in enumerate(nl_block.samples):\n",
    "                x, y, z = (\n",
    "                    nl_block.values[isample, 0],\n",
    "                    nl_block.values[isample, 1],\n",
    "                    nl_block.values[isample, 2],\n",
    "                )\n",
    "                sample_value = compute_moments_inefficient_implementation(\n",
    "                    A, np.array([x, y, z]), maxdeg\n",
    "                )  # moments for the pair\n",
    "                # this is a (maxdeg+1, maxdeg+1, maxdeg+1) matrix\n",
    "                desc_block_values.append(\n",
    "                    sample_value.reshape((sample_value.shape) + (1,))\n",
    "                )\n",
    "\n",
    "#                 print(sample_value.shape)\n",
    "#             desc_blocks.append(TensorBlock(values = np.asarray(desc_block_values),\n",
    "#                                       samples = nl_block.samples,\n",
    "#                                       components = [Labels(),Labels(),Labels()]\n",
    "#                                       properties = [Labels([\"dummy\"], [\"0\"])]\n",
    "\n",
    "\n",
    "#                                         )\n",
    "\n",
    "#                          )\n",
    "# pair_aniso_desc = TensorMap(nl.keys, desc_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3ad37e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labels([(1, 0), (8, 0)],\n",
       "       dtype=[('species_second_atom', '<i4'), ('distance', '<i4')])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the final descriptor, we just need to sum over the neighbor species\n",
    "\n",
    "desc_blocks = []\n",
    "for center_species in global_species:\n",
    "    for neighbor_species in global_species:\n",
    "        if (center_species, neighbor_species) in pair_aniso_desc.keys:\n",
    "            desc_samples = []\n",
    "            pair_block = pair_aniso_desc.block(\n",
    "                species_first_atom=center_species, species_second_atom=neighbor_species\n",
    "            )\n",
    "            desc_block_values = []\n",
    "            desc_samples = list(\n",
    "                product(\n",
    "                    np.unique(block.samples[\"structure\"]),\n",
    "                    np.unique(block.samples[\"center\"]),\n",
    "                )\n",
    "            )\n",
    "            for isample, sample in enumerate(desc_samples):\n",
    "                sample_idx = [\n",
    "                    idx\n",
    "                    for idx, tup in enumerate(nl_block.samples)\n",
    "                    if tup[\"structure\"] == sample[0] and tup[\"center\"] == sample[1]\n",
    "                ]\n",
    "\n",
    "                sample_value += desc_block_values.append(\n",
    "                    nl_block.values[sample_idx].sum(axis=0)\n",
    "                )\n",
    "                desc_block_values.append(sample_value)\n",
    "#             desc_blocks.append(TensorBlock(values = np.asarray(desc_block_values),\n",
    "#                                       samples = Labels([\"structure\", \"central_atom\"], desc_samples),\n",
    "#                                       components = [Labels()]\n",
    "#                                       properties = [Labels()]\n",
    "\n",
    "\n",
    "#                                         )\n",
    "\n",
    "aniso_desc = TensorMap(\n",
    "    Labels(\"center_species\", np.asarray(global_species, dtype=int32)), desc_blocks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab8fac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
